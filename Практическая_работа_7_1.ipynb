{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPhUI33ON1y9weuxLMgA5Ug",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadya-az/artificial_neural_networks/blob/main/%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_7_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этап 1. Выбор и обработка исходных данных. Разделение на обучающую и тестовую выборку"
      ],
      "metadata": {
        "id": "oILh875byqag"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_YgYXFAybBh",
        "outputId": "63eedf2d-44b9-41d8-cb61-0eda6b5a26e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patchify\n",
        "\n",
        "!pip install tensorflow==2.9.0\n",
        "!pip install -U -q segmentation-models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1DMyL8uYy2ar",
        "outputId": "bdbeae60-f952-449a-8915-67b082633e99"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting patchify\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from patchify) (1.22.4)\n",
            "Installing collected packages: patchify\n",
            "Successfully installed patchify-0.2.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.9.0\n",
            "  Downloading tensorflow-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.6.3)\n",
            "Collecting flatbuffers<2,>=1.12 (from tensorflow==2.9.0)\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (3.8.0)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.0)\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.9.0)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (16.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (23.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.16.0)\n",
            "Collecting tensorboard<2.10,>=2.9 (from tensorflow==2.9.0)\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (0.32.0)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.0)\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.0) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.0) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.17.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.10,>=2.9->tensorflow==2.9.0)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.4.3)\n",
            "Collecting protobuf>=3.9.2 (from tensorflow==2.9.0)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.27.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.0)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.2.2)\n",
            "Installing collected packages: keras, flatbuffers, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.2\n",
            "    Uninstalling tensorboard-2.12.2:\n",
            "      Successfully uninstalled tensorboard-2.12.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flatbuffers-1.12 google-auth-oauthlib-0.4.6 keras-2.9.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorflow-2.9.0 tensorflow-estimator-2.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split_folders"
      ],
      "metadata": {
        "id": "vmZ-g3s0BIiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from patchify import patchify\n",
        "from PIL import Image\n",
        "\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "import segmentation_models as sm\n",
        "from keras.metrics import MeanIoU\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "import splitfolders"
      ],
      "metadata": {
        "id": "2ycKJUluy6aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_directory = '/content/drive/MyDrive/Semantic_segmentation_dataset'\n",
        "\n",
        "patch_size = 256"
      ],
      "metadata": {
        "id": "CVq5EMlez9y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dataset = []  \n",
        "for path, subdirs, files in os.walk(root_directory):\n",
        "    print(path)  \n",
        "    dirname = path.split(os.path.sep)[-1]\n",
        "    if dirname == 'images':   \n",
        "        images = os.listdir(path)\n",
        "        for i, image_name in enumerate(images):  \n",
        "            if image_name.endswith(\".jpg\"):   \n",
        "                image = cv2.imread(path+\"/\"+image_name, 1)  \n",
        "                SIZE_X = (image.shape[1]//patch_size)*patch_size \n",
        "                SIZE_Y = (image.shape[0]//patch_size)*patch_size  \n",
        "                image = Image.fromarray(image)\n",
        "                image = image.crop((0 ,0, SIZE_X, SIZE_Y))  \n",
        "                image = np.array(image)             \n",
        "       \n",
        "                # Разделяем изображение на части\n",
        "                print(\"Now patchifying image:\", path+\"/\"+image_name)\n",
        "                patches_img = patchify(image, (patch_size, patch_size, 3), step=patch_size)  #Step=256 for 256 patches means no overlap\n",
        "        \n",
        "                for i in range(patches_img.shape[0]):\n",
        "                    for j in range(patches_img.shape[1]):\n",
        "                        \n",
        "                        single_patch_img = patches_img[i,j,:,:]\n",
        "                        single_patch_img = single_patch_img[0] # Убираем лишние ненужные каналы, которые добавляет patchify.                              \n",
        "                        # image_dataset.append(single_patch_img)\n",
        "          \n",
        "                        cv2.imwrite(root_directory+\"/Data/Image/\" + image_name + \n",
        "                                   \"_patch_\" + str(i) + str(j) + \".jpg\", single_patch_img)\n",
        "                      "
      ],
      "metadata": {
        "id": "pV_iwubjz_iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_dataset = []  \n",
        "for path, subdirs, files in os.walk(root_directory):\n",
        "    print(path)  \n",
        "    dirname = path.split(os.path.sep)[-1]\n",
        "    if dirname == 'masks': \n",
        "        masks = os.listdir(path)  \n",
        "        for i, mask_name in enumerate(masks):  \n",
        "            if mask_name.endswith(\".png\"):  \n",
        "               \n",
        "                mask = cv2.imread(path+\"/\"+mask_name, 1)\n",
        "                SIZE_X = (mask.shape[1]//patch_size)*patch_size\n",
        "                SIZE_Y = (mask.shape[0]//patch_size)*patch_size\n",
        "                mask = Image.fromarray(mask)\n",
        "                mask = mask.crop((0 ,0, SIZE_X, SIZE_Y))\n",
        "                mask = np.array(mask)             \n",
        "       \n",
        "                print(\"Now patchifying mask:\", path+\"/\"+mask_name)\n",
        "                patches_mask = patchify(mask, (patch_size, patch_size, 3), step=patch_size)\n",
        "        \n",
        "                for i in range(patches_mask.shape[0]):\n",
        "                    for j in range(patches_mask.shape[1]):\n",
        "                        \n",
        "                        single_patch_mask = patches_mask[i,j,:,:]\n",
        "                        single_patch_mask = single_patch_mask[0]                               \n",
        "\n",
        "                        cv2.imwrite(root_directory+\"/Data/Masks/\" + mask_name + \n",
        "                                   \"_patch_\" + str(i) + str(j) + \".png\", single_patch_mask)\n",
        " \n"
      ],
      "metadata": {
        "id": "Be9BkmAc0EmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_dir = r'/content/drive/MyDrive/Semantic_segmentation_dataset/Data/Image/'\n",
        "train_mask_dir = r'/content/drive/MyDrive/Semantic_segmentation_dataset/Data/Masks/'"
      ],
      "metadata": {
        "id": "fSen_rMF0qMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_list = sorted(os.listdir(train_img_dir))\n",
        "msk_list = sorted(os.listdir(train_mask_dir))\n",
        "\n",
        "num_images = len(os.listdir(train_img_dir))\n",
        "\n",
        "print(img_list, msk_list)\n",
        "\n",
        "print(len(img_list), len(msk_list))"
      ],
      "metadata": {
        "id": "u8YmpW460wye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "img_num = random.randint(0, num_images-1)\n",
        "\n",
        "img_for_plot = cv2.imread(train_img_dir+img_list[img_num])\n",
        "\n",
        "img_for_plot = cv2.cvtColor(img_for_plot, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "mask_for_plot =cv2.imread(train_mask_dir+msk_list[img_num])\n",
        "mask_for_plot = cv2.cvtColor(mask_for_plot, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "fig=plt.figure(figsize=(12,8), dpi= 100, facecolor='w', edgecolor='k')\n",
        " \n",
        "figure, axis = plt.subplots(1, 2)\n",
        "\n",
        "axis[0].imshow(img_for_plot, cmap=plt.get_cmap('gray'),vmin=0,vmax=100)\n",
        "axis[0].set_title('Image')\n",
        "\n",
        "axis[1].imshow(mask_for_plot)\n",
        "axis[1].set_title('Mask')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "fig=plt.figure(figsize=(12,8), dpi= 100, facecolor='w', edgecolor='k')\n",
        " \n",
        "figure, axis = plt.subplots(1, 3)\n",
        "\n",
        "axis[0].imshow(img_for_plot[:,:,0])\n",
        "axis[0].set_title('Image_Ch=1')\n",
        "\n",
        "axis[1].imshow(img_for_plot[:,:,1])\n",
        "axis[1].set_title('Image_Ch=2')\n",
        "\n",
        "axis[2].imshow(img_for_plot[:,:,2])\n",
        "axis[2].set_title('Image_Ch=3')\n",
        "\n",
        "# Combine all the operations and display\n",
        "plt.show()\n",
        "\n",
        "fig=plt.figure(figsize=(12,8), dpi= 100, facecolor='w', edgecolor='k')\n",
        " \n",
        "figure, axis = plt.subplots(1, 3)\n",
        "\n",
        "axis[0].imshow(mask_for_plot[:,:,0])\n",
        "axis[0].set_title(\"Mask_Ch=1\")\n",
        "\n",
        "axis[1].imshow(mask_for_plot[:,:,1])\n",
        "axis[1].set_title(\"Mask_Ch=2\")\n",
        "\n",
        "axis[2].imshow(mask_for_plot[:,:,2])\n",
        "axis[2].set_title(\"Mask_Ch=3\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E0YKT2oy00U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder = r'/content/drive/MyDrive/Semantic_segmentation_dataset/Data/'\n",
        "output_folder = r'/content/drive/MyDrive/Semantic_segmentation_dataset/output/'\n",
        "\n",
        "splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.75, .25), group_prefix=None)"
      ],
      "metadata": {
        "id": "XKurCuy4BRky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этап 2. Предобработка обучающей выборки. Разработка архитектуры модели"
      ],
      "metadata": {
        "id": "adizD7EnAvEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Building = '#3C1098'.lstrip('#')\n",
        "Building = np.array(tuple(int(Building[i:i+2], 16) for i in (0, 2, 4))) # 60, 16, 152\n",
        "\n",
        "Land = '#8429F6'.lstrip('#')\n",
        "Land = np.array(tuple(int(Land[i:i+2], 16) for i in (0, 2, 4))) #132, 41, 246\n",
        "\n",
        "Road = '#6EC1E4'.lstrip('#') \n",
        "Road = np.array(tuple(int(Road[i:i+2], 16) for i in (0, 2, 4))) #110, 193, 228\n",
        "\n",
        "Vegetation =  'FEDD3A'.lstrip('#') \n",
        "Vegetation = np.array(tuple(int(Vegetation[i:i+2], 16) for i in (0, 2, 4))) #254, 221, 58\n",
        "\n",
        "Water = 'E2A929'.lstrip('#') \n",
        "Water = np.array(tuple(int(Water[i:i+2], 16) for i in (0, 2, 4))) #226, 169, 41\n",
        "\n",
        "Unlabeled = '#9B9B9B'.lstrip('#') \n",
        "Unlabeled = np.array(tuple(int(Unlabeled[i:i+2], 16) for i in (0, 2, 4))) #155, 155, 155"
      ],
      "metadata": {
        "id": "aRt-YXMj_Jev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb_to_2D_label(label):\n",
        "    \"\"\"\n",
        "    Замена значений каждого пикселя маски в формате RGB на целое число \n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    if len(label.shape) == 3: \n",
        "        label = label[:,:,:3]\n",
        "    if len(label.shape) == 4: \n",
        "        label = label[:,:,:,:3]\n",
        "\n",
        "    label_seg = np.zeros(label.shape,dtype=np.uint8)\n",
        "    label_seg [np.all(label == Building,axis=-1)] = 0\n",
        "    label_seg [np.all(label==Land,axis=-1)] = 1\n",
        "    label_seg [np.all(label==Road,axis=-1)] = 2\n",
        "    label_seg [np.all(label==Vegetation,axis=-1)] = 3\n",
        "    label_seg [np.all(label==Water,axis=-1)] = 4\n",
        "    label_seg [np.all(label==Unlabeled,axis=-1)] = 5\n",
        "\n",
        "    if len(label.shape) == 3: \n",
        "        label_seg = label_seg[:,:,0]\n",
        "    if len(label.shape) == 4: \n",
        "        label_seg = label_seg[:,:,:,0]\n",
        "        \n",
        "    return label_seg"
      ],
      "metadata": {
        "id": "mBEHzIpgA3hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#Use this to preprocess input for transfer learning\n",
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "def preprocess_data(img, mask, num_class):\n",
        "    img = scaler.fit_transform(img.reshape(-1, img.shape[-1])).reshape(img.shape)\n",
        "    img = preprocess_input(img) \n",
        "    mask = rgb_to_2D_label(mask)\n",
        "    mask = to_categorical(mask, num_class)\n",
        "      \n",
        "    return (img, mask)\n"
      ],
      "metadata": {
        "id": "eCepF1FgA_gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed=24\n",
        "batch_size= 16\n",
        "num_classes=6"
      ],
      "metadata": {
        "id": "CNnU2xm1EKS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "def trainGenerator(train_img_path, train_mask_path, num_class):\n",
        "    img_data_gen_args = dict(horizontal_flip=True,\n",
        "                      vertical_flip=True)\n",
        "    \n",
        "    image_datagen = ImageDataGenerator(**img_data_gen_args)\n",
        "    mask_datagen = ImageDataGenerator(**img_data_gen_args)\n",
        "    print(train_img_path)\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_img_path,\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    \n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        train_mask_path,\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    \n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    \n",
        "    for (img, mask) in train_generator:\n",
        "        img, mask = preprocess_data(img, mask, num_class)\n",
        "        yield (img, mask)"
      ],
      "metadata": {
        "id": "krzTc2jHEQKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_path = r'/content/drive/MyDrive/Semantic_segmentation_dataset/output/train/'\n",
        "train_mask_path = r'/content/drive/MyDrive/Semantic_segmentation_dataset/output/train/'\n",
        "\n",
        "train_img_gen = trainGenerator(train_img_path, train_mask_path, num_class=6)\n",
        "\n",
        "\n",
        "val_img_path = r'/content/drive/MyDrive/Semantic_segmentation_dataset/output/val/'\n",
        "val_mask_path = r'/content/drive/MyDrive/Semantic_segmentation_dataset/output/val/'\n",
        "\n",
        "val_img_gen = trainGenerator(val_img_path, val_mask_path, num_class=6)"
      ],
      "metadata": {
        "id": "cLKXLif6HKVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = train_img_gen.__next__()\n",
        "\n",
        "for i in range(0,3):\n",
        "    image = x[i][:,:,0]\n",
        "    mask = np.argmax(y[i], axis=2)\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image)\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mask)\n",
        "    plt.show()\n",
        "\n",
        "x_val, y_val = val_img_gen.__next__()\n",
        "\n",
        "for i in range(0,3):\n",
        "    image = x_val[i][:,:,0]\n",
        "    mask = np.argmax(y_val[i], axis=2)\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image)\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(mask)\n",
        "    plt.show()\n",
        "\n",
        "labels, count = np.unique(mask, return_counts=True) #Check for each channel. All chanels are identical\n",
        "\n",
        "print(\"Unique labels in label dataset are: \", np.unique(labels))"
      ],
      "metadata": {
        "id": "hzBtO_3NHe0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_imgs = len(os.listdir(r'/content/drive/MyDrive/Semantic_segmentation_dataset/output/train/Image/'))\n",
        "num_val_images = len(os.listdir(r'/content/drive/MyDrive/Semantic_segmentation_dataset/output/val/Image/'))\n",
        "steps_per_epoch = num_train_imgs//batch_size\n",
        "val_steps_per_epoch = num_val_images//batch_size\n",
        "\n",
        "\n",
        "IMG_HEIGHT = x.shape[1]\n",
        "IMG_WIDTH  = x.shape[2]\n",
        "IMG_CHANNELS = x.shape[3]\n",
        "\n",
        "n_classes=6\n",
        "\n",
        "print(num_train_imgs, steps_per_epoch, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "print(num_train_imgs, num_val_images, steps_per_epoch, val_steps_per_epoch, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)"
      ],
      "metadata": {
        "id": "FCBtJqTIpZ-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этап 3"
      ],
      "metadata": {
        "id": "LGE9Rznm5PFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras import backend as K\n",
        "\n",
        "def jacard_coef(y_true, y_pred): # https://ru.wikipedia.org/wiki/Коэффициент_Жаккара\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "metrics=['accuracy', jacard_coef]"
      ],
      "metadata": {
        "id": "z_Xaue-T5NoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet_backbone = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=n_classes, activation='softmax')\n",
        "\n",
        "model_resnet_backbone.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)\n",
        "\n",
        "print(model_resnet_backbone.summary())"
      ],
      "metadata": {
        "id": "2UheDyxL5MOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2=model_resnet_backbone.fit(\n",
        "          train_img_gen,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=val_img_gen,\n",
        "          validation_steps=val_steps_per_epoch)"
      ],
      "metadata": {
        "id": "r1TAzXVi52OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet_backbone.save('/content/drive/MyDrive/mask_jac.h5')"
      ],
      "metadata": {
        "id": "3UEhzD4_G5XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/mask_jac.h5', compile=False)\n",
        "                 \n",
        "patch_size = 256\n",
        "\n",
        "n_classes = 6"
      ],
      "metadata": {
        "id": "eLyItQEWG72E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "a = 0\n",
        "while i < 61:\n",
        "  test_image_batch, test_mask_batch = train_img_gen.__next__()\n",
        "  test_mask_batch_argmax = np.argmax(test_mask_batch, axis=3) \n",
        "  test_pred_batch = model.predict(test_image_batch)\n",
        "  test_pred_batch_argmax = np.argmax(test_pred_batch, axis=3)\n",
        "  n_classes = 6\n",
        "  IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "  IOU_keras.update_state(test_pred_batch_argmax, test_mask_batch_argmax)\n",
        "  i += 1\n",
        "  a += IOU_keras.result().numpy()\n",
        "  print(i)\n",
        "  print(a)\n",
        "\n",
        "print(\"Mean IoU =\", a/(i)) "
      ],
      "metadata": {
        "id": "p9dkprhcHDqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img_num in range(test_image_batch.shape[0]-1):   \n",
        "\n",
        "    fig=plt.figure(figsize=(12,8), facecolor='w', edgecolor='k')\n",
        "\n",
        "    figure, axis = plt.subplots(1, 4)\n",
        "    fig.tight_layout()\n",
        "\n",
        "    axis[0].imshow(test_image_batch[img_num][:,:,0])\n",
        "    axis[0].set_title('Test_Image_Ch=1', fontsize = 8)\n",
        "    axis[0].axes.xaxis.set_visible(False)\n",
        "    axis[0].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[1].imshow(test_image_batch[img_num][:,:,1])\n",
        "    axis[1].set_title('Test_Image_Ch=2', fontsize = 8)\n",
        "    axis[1].axes.xaxis.set_visible(False)\n",
        "    axis[1].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[2].imshow(test_mask_batch_argmax[img_num])\n",
        "    axis[2].set_title(\"Testing Label\", fontsize = 8)\n",
        "    axis[2].axes.xaxis.set_visible(False)\n",
        "    axis[2].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[3].imshow(test_pred_batch_argmax[img_num])\n",
        "    axis[3].set_title(\"Prediction on test image\", fontsize = 8)\n",
        "    axis[3].axes.xaxis.set_visible(False)\n",
        "    axis[3].axes.yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "h87Hk15PHH5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = 0\n",
        "b = 0\n",
        "while g < 12:\n",
        "  test_image_batch, test_mask_batch = val_img_gen.__next__()\n",
        "  test_mask_batch_argmax = np.argmax(test_mask_batch, axis=3) \n",
        "  test_pred_batch = model.predict(test_image_batch)\n",
        "  test_pred_batch_argmax = np.argmax(test_pred_batch, axis=3)\n",
        "  n_classes = 6\n",
        "  IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "  IOU_keras.update_state(test_pred_batch_argmax, test_mask_batch_argmax)\n",
        "  g += 1\n",
        "  b += IOU_keras.result().numpy()\n",
        "  print(g)\n",
        "  print(b)\n",
        "\n",
        "print(\"Mean IoU =\", b/(g))"
      ],
      "metadata": {
        "id": "vySy2j6sHOhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img_num in range(test_image_batch.shape[0]-1):   \n",
        "\n",
        "    fig=plt.figure(figsize=(12,8), facecolor='w', edgecolor='k')\n",
        "\n",
        "    figure, axis = plt.subplots(1, 4)\n",
        "    fig.tight_layout()\n",
        "\n",
        "    axis[0].imshow(test_image_batch[img_num][:,:,0])\n",
        "    axis[0].set_title('Test_Image_Ch=1', fontsize = 8)\n",
        "    axis[0].axes.xaxis.set_visible(False)\n",
        "    axis[0].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[1].imshow(test_image_batch[img_num][:,:,1])\n",
        "    axis[1].set_title('Test_Image_Ch=2', fontsize = 8)\n",
        "    axis[1].axes.xaxis.set_visible(False)\n",
        "    axis[1].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[2].imshow(test_mask_batch_argmax[img_num])\n",
        "    axis[2].set_title(\"Testing Label\", fontsize = 8)\n",
        "    axis[2].axes.xaxis.set_visible(False)\n",
        "    axis[2].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[3].imshow(test_pred_batch_argmax[img_num])\n",
        "    axis[3].set_title(\"Prediction on test image\", fontsize = 8)\n",
        "    axis[3].axes.xaxis.set_visible(False)\n",
        "    axis[3].axes.yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "NFTwQMhDHPtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Среднее значение IoU обучающей выборке = \", round((a/(i))*100, 2), '%')\n",
        "print(\"Среднее значение IoU тестовой выборке = \", round((b/(g))*100, 2), '%')"
      ],
      "metadata": {
        "id": "4K2M2QCWHTt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "Giz6Fu5HnpuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_los(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
        "\n",
        "metrics_dice=['accuracy', dice_los, sm.metrics.Precision()]"
      ],
      "metadata": {
        "id": "4wcq6NfToodf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet_dice = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=n_classes, activation='softmax')\n",
        "\n",
        "model_resnet_dice.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics_dice)\n",
        "\n",
        "print(model_resnet_dice.summary())"
      ],
      "metadata": {
        "id": "yNtilkWEsPBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history3 = model_resnet_dice.fit(\n",
        "          train_img_gen,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=val_img_gen,\n",
        "          validation_steps = val_steps_per_epoch)"
      ],
      "metadata": {
        "id": "lOeTl5yesZH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet_dice.save('/content/drive/MyDrive/dice.h5')"
      ],
      "metadata": {
        "id": "S732WpbkzSlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_dice = load_model('/content/drive/MyDrive/dice.h5', compile=False)\n",
        "                 \n",
        "patch_size = 256\n",
        "\n",
        "num_classes = 6"
      ],
      "metadata": {
        "id": "fFNw4hiSzbfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "a = 0\n",
        "while i < 61:\n",
        "  test_image_batch, test_mask_batch = train_img_gen.__next__()\n",
        "  test_mask_batch_argmax = np.argmax(test_mask_batch, axis=3) \n",
        "  test_pred_batch = model_dice.predict(test_image_batch)\n",
        "  test_pred_batch_argmax = np.argmax(test_pred_batch, axis=3)\n",
        "  n_classes = 6\n",
        "  IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "  IOU_keras.update_state(test_pred_batch_argmax, test_mask_batch_argmax)\n",
        "  i += 1\n",
        "  a += IOU_keras.result().numpy()\n",
        "  print(i)\n",
        "  print(a)\n",
        "\n",
        "print(\"Mean IoU =\", a/(i))"
      ],
      "metadata": {
        "id": "vjbSVl7ZzfIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img_num in range(test_image_batch.shape[0]-1):   \n",
        "\n",
        "    fig=plt.figure(figsize=(12,8), facecolor='w', edgecolor='k')\n",
        "\n",
        "    figure, axis = plt.subplots(1, 4)\n",
        "    fig.tight_layout()\n",
        "\n",
        "    axis[0].imshow(test_image_batch[img_num][:,:,0])\n",
        "    axis[0].set_title('Test_Image_Ch=1', fontsize = 8)\n",
        "    axis[0].axes.xaxis.set_visible(False)\n",
        "    axis[0].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[1].imshow(test_image_batch[img_num][:,:,1])\n",
        "    axis[1].set_title('Test_Image_Ch=2', fontsize = 8)\n",
        "    axis[1].axes.xaxis.set_visible(False)\n",
        "    axis[1].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[2].imshow(test_mask_batch_argmax[img_num])\n",
        "    axis[2].set_title(\"Testing Label\", fontsize = 8)\n",
        "    axis[2].axes.xaxis.set_visible(False)\n",
        "    axis[2].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[3].imshow(test_pred_batch_argmax[img_num])\n",
        "    axis[3].set_title(\"Prediction on test image\", fontsize = 8)\n",
        "    axis[3].axes.xaxis.set_visible(False)\n",
        "    axis[3].axes.yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oEiHHuXVzodZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = 0\n",
        "b = 0\n",
        "while g < 12:\n",
        "  test_image_batch, test_mask_batch = val_img_gen.__next__()\n",
        "  test_mask_batch_argmax = np.argmax(test_mask_batch, axis=3) \n",
        "  test_pred_batch = model_dice.predict(test_image_batch)\n",
        "  test_pred_batch_argmax = np.argmax(test_pred_batch, axis=3)\n",
        "  n_classes = 6\n",
        "  IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "  IOU_keras.update_state(test_pred_batch_argmax, test_mask_batch_argmax)\n",
        "  g += 1\n",
        "  b += IOU_keras.result().numpy()\n",
        "  print(g)\n",
        "  print(b)\n",
        "\n",
        "print(\"Mean IoU =\", b/(g))"
      ],
      "metadata": {
        "id": "NWbk2AWIzuZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img_num in range(test_image_batch.shape[0]-1):   \n",
        "\n",
        "    fig=plt.figure(figsize=(12,8), facecolor='w', edgecolor='k')\n",
        "\n",
        "    figure, axis = plt.subplots(1, 4)\n",
        "    fig.tight_layout()\n",
        "\n",
        "    axis[0].imshow(test_image_batch[img_num][:,:,0])\n",
        "    axis[0].set_title('Test_Image_Ch=1', fontsize = 8)\n",
        "    axis[0].axes.xaxis.set_visible(False)\n",
        "    axis[0].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[1].imshow(test_image_batch[img_num][:,:,1])\n",
        "    axis[1].set_title('Test_Image_Ch=2', fontsize = 8)\n",
        "    axis[1].axes.xaxis.set_visible(False)\n",
        "    axis[1].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[2].imshow(test_mask_batch_argmax[img_num])\n",
        "    axis[2].set_title(\"Testing Label\", fontsize = 8)\n",
        "    axis[2].axes.xaxis.set_visible(False)\n",
        "    axis[2].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[3].imshow(test_pred_batch_argmax[img_num])\n",
        "    axis[3].set_title(\"Prediction on test image\", fontsize = 8)\n",
        "    axis[3].axes.xaxis.set_visible(False)\n",
        "    axis[3].axes.yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iubrymhVzzYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Среднее значение IoU обучающей выборке model_dice = \", round((a/(i))*100, 2), '%')\n",
        "print(\"Среднее значение IoU тестовой выборке model_dice = \", round((b/(g))*100, 2), '%')"
      ],
      "metadata": {
        "id": "mHkrorBxz2eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этап 4"
      ],
      "metadata": {
        "id": "UBLT_dAhz9e6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history2.history['jacard_coef']\n",
        "val_acc = history2.history['val_jacard_coef']\n",
        "\n",
        "plt.plot(acc, 'y', label='Training IoU')\n",
        "plt.plot(val_acc, 'r', label='Validation IoU')\n",
        "plt.title('Training and validation IoU')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IoU')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x2gEjirEz72j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img_num in range(test_image_batch.shape[0]-1):   \n",
        "\n",
        "    fig=plt.figure(figsize=(12,8), facecolor='w', edgecolor='k')\n",
        "\n",
        "    figure, axis = plt.subplots(1, 4)\n",
        "    fig.tight_layout()\n",
        "\n",
        "    axis[0].imshow(test_image_batch[img_num][:,:,0])\n",
        "    axis[0].set_title('Test_Image_Ch=1', fontsize = 8)\n",
        "    axis[0].axes.xaxis.set_visible(False)\n",
        "    axis[0].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[1].imshow(test_image_batch[img_num][:,:,1])\n",
        "    axis[1].set_title('Test_Image_Ch=2', fontsize = 8)\n",
        "    axis[1].axes.xaxis.set_visible(False)\n",
        "    axis[1].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[2].imshow(test_mask_batch_argmax[img_num])\n",
        "    axis[2].set_title(\"Testing Label\", fontsize = 8)\n",
        "    axis[2].axes.xaxis.set_visible(False)\n",
        "    axis[2].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[3].imshow(test_pred_batch_argmax[img_num])\n",
        "    axis[3].set_title(\"Prediction on test image\", fontsize = 8)\n",
        "    axis[3].axes.xaxis.set_visible(False)\n",
        "    axis[3].axes.yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "JwkF4mu-0DAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = history3\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FnLSuJkn0GLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['dice_los']\n",
        "val_acc = history.history['val_dice_los']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training FScore')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation FScore')\n",
        "plt.title('Training and validation FScore')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('FScore')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E0Yqlf210NsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img_num in range(test_image_batch.shape[0]-1):   \n",
        "\n",
        "    fig=plt.figure(figsize=(12,8), facecolor='w', edgecolor='k')\n",
        "\n",
        "    figure, axis = plt.subplots(1, 4)\n",
        "    fig.tight_layout()\n",
        "\n",
        "    axis[0].imshow(test_image_batch[img_num][:,:,0])\n",
        "    axis[0].set_title('Test_Image_Ch=1', fontsize = 8)\n",
        "    axis[0].axes.xaxis.set_visible(False)\n",
        "    axis[0].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[1].imshow(test_image_batch[img_num][:,:,1])\n",
        "    axis[1].set_title('Test_Image_Ch=2', fontsize = 8)\n",
        "    axis[1].axes.xaxis.set_visible(False)\n",
        "    axis[1].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[2].imshow(test_mask_batch_argmax[img_num])\n",
        "    axis[2].set_title(\"Testing Label\", fontsize = 8)\n",
        "    axis[2].axes.xaxis.set_visible(False)\n",
        "    axis[2].axes.yaxis.set_visible(False)\n",
        "\n",
        "    axis[3].imshow(test_pred_batch_argmax[img_num])\n",
        "    axis[3].set_title(\"Prediction on test image\", fontsize = 8)\n",
        "    axis[3].axes.xaxis.set_visible(False)\n",
        "    axis[3].axes.yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "s_TfcTax0UCX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}